{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4Ha8o4-qDm8"
      },
      "source": [
        "# Spatial Joins Exercises\n",
        "\n",
        "Here\\'s a reminder of some of the functions we have seen. Hint: they\n",
        "should be useful for the exercises!\n",
        "\n",
        "-   `sum(expression)`: aggregate to\n",
        "    return a sum for a set of records\n",
        "-   `count(expression)`: aggregate to\n",
        "    return the size of a set of records\n",
        "-   `ST_Area(geometry)` returns the\n",
        "    area of the polygons\n",
        "-   `ST_AsText(geometry)` returns WKT `text`\n",
        "-   `ST_Contains(geometry A, geometry B)` returns the true if geometry A contains geometry B\n",
        "-   `ST_Distance(geometry A, geometry B)` returns the minimum distance between geometry A and\n",
        "    geometry B\n",
        "-   `ST_DWithin(geometry A, geometry B, radius)` returns the true if geometry A is radius distance or less from geometry B\n",
        "-   `ST_GeomFromText(text)` returns `geometry`\n",
        "-   `ST_Intersects(geometry A, geometry B)` returns the true if geometry A intersects geometry B\n",
        "-   `ST_Length(linestring)` returns the length of the linestring\n",
        "-   `ST_Touches(geometry A, geometry B)` returns the true if the boundary of geometry A touches geometry B\n",
        "-   `ST_Within(geometry A, geometry B)` returns the true if geometry A is within geometry B\n",
        "\n",
        "\n",
        "Uncomment and run the following cell to install the required packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aV1ntEByqDm-",
        "outputId": "f862e171-32f9-4f8c-84bc-ac9fecae5798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sql extension is already loaded. To reload it, use:\n",
            "  %reload_ext sql\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sql/connection.py\", line 45, in __init__\n",
            "    engine = sqlalchemy.create_engine(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 2, in create_engine\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/deprecations.py\", line 281, in warned\n",
            "    return fn(*args, **kwargs)  # type: ignore[no-any-return]\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/create.py\", line 553, in create_engine\n",
            "    entrypoint = u._get_entrypoint()\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/url.py\", line 772, in _get_entrypoint\n",
            "    cls = registry.load(name)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/langhelpers.py\", line 375, in load\n",
            "    raise exc.NoSuchModuleError(\n",
            "sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:duckdb\n",
            "\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sql/magic.py\", line 196, in execute\n",
            "    conn = sql.connection.Connection.set(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sql/connection.py\", line 70, in set\n",
            "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sql/connection.py\", line 45, in __init__\n",
            "    engine = sqlalchemy.create_engine(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 2, in create_engine\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/deprecations.py\", line 281, in warned\n",
            "    return fn(*args, **kwargs)  # type: ignore[no-any-return]\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/create.py\", line 553, in create_engine\n",
            "    entrypoint = u._get_entrypoint()\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/url.py\", line 772, in _get_entrypoint\n",
            "    cls = registry.load(name)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/langhelpers.py\", line 375, in load\n",
            "    raise exc.NoSuchModuleError(\n",
            "sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:duckdb\n",
            "\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ],
      "source": [
        "#  %pip install duckdb leafmap lonboard\n",
        "import duckdb\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "%load_ext sql\n",
        "%sql duckdb:///:memory:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6UDaruQqDm-"
      },
      "source": [
        "Download the [nyc_data.zip](https://github.com/opengeos/data/raw/main/duckdb/nyc_data.zip) dataset using leafmap. The zip file contains the following datasets. Create a new DuckDB database and import the datasets into the database. Each dataset should be imported into a separate table.\n",
        "\n",
        "- nyc_census_blocks\n",
        "- nyc_homicides\n",
        "- nyc_neighborhoods\n",
        "- nyc_streets\n",
        "- nyc_subway_stations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/opengeos/data/raw/main/duckdb/nyc_data.zip'\n",
        "leafmap.download_file(url, unzip=True, overwrite=True)"
      ],
      "metadata": {
        "id": "vtL8bCFlsIqW",
        "outputId": "ca1a11c7-90df-4b67-a97e-596e14a5f855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/opengeos/data/raw/main/duckdb/nyc_data.zip\n",
            "To: /content/nyc_data.zip\n",
            "100%|██████████| 8.73M/8.73M [00:00<00:00, 20.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/nyc_data.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHf3pjCYqDm-"
      },
      "source": [
        "1. **What subway station is in \\'Little Italy\\'? What subway route is it on?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# 解压 ZIP 文件\n",
        "zip_file_path = \"/content/nyc_data.zip\"\n",
        "unzipped_folder = \"/content/nyc_data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzipped_folder)\n",
        "\n",
        "# 列出解压后的文件\n",
        "import os\n",
        "files = os.listdir(unzipped_folder)\n",
        "print(\"解压后的文件列表：\", files)"
      ],
      "metadata": {
        "id": "GasPPNXgwG6q",
        "outputId": "260e49d7-eece-4d8e-f3cc-34847e33eb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/nyc_data/nyc_census_blocks.dbf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-15874f888f9f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munzipped_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 列出解压后的文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/nyc_data/nyc_census_blocks.dbf'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con = duckdb.connect('nyc_data')\n",
        "con.install_extension('spatial')\n",
        "con.load_extension('spatial')\n",
        "con.sql(\"SHOW TABLES;\")"
      ],
      "metadata": {
        "id": "EvKUqQCCvLK7",
        "outputId": "f30ec3a8-31e4-4e7f-d5e0-85be7ea4cdce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "┌─────────┐\n",
              "│  name   │\n",
              "│ varchar │\n",
              "├─────────┤\n",
              "│ 0 rows  │\n",
              "└─────────┘"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CNodOMoVqDm_",
        "outputId": "68f0ff47-49fd-4005-d7c8-67f98cba2dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sql/magic.py\", line 196, in execute\n",
            "    conn = sql.connection.Connection.set(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sql/connection.py\", line 82, in set\n",
            "    raise ConnectionError(\n",
            "sql.connection.ConnectionError: Environment variable $DATABASE_URL not set, and no connect string given.\n",
            "\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ],
      "source": [
        "%%sql\n",
        "SELECT * FROM nyc_subway_stations LIMIT 10;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ROuoXcqDm_"
      },
      "source": [
        "2. **What are all the neighborhoods served by the 6-train?** (Hint: The `routes` column in the `nyc_subway_stations` table has values like \\'B,D,6,V\\' and \\'C,6\\')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuVuskZzqDm_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYeh_PZyqDm_"
      },
      "source": [
        "3. **After 9/11, the \\'Battery Park\\' neighborhood was off limits for several days. How many people had to be evacuated?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agda1MbFqDm_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmP-kIALqDm_"
      },
      "source": [
        "4. **What neighborhood has the highest population density (persons/km2)?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DJUiFzhqDnA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyBsOqFeqDnA"
      },
      "source": [
        "When you're finished, you can check your answers [here](https://postgis.net/workshops/postgis-intro/joins_exercises.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCEl3e8XqDnA"
      },
      "source": [
        "# Ship-to-Ship Transfer Detection\n",
        "\n",
        "Now for a less structured exercise. We're going to look at ship-to-ship transfers. The idea is that two ships meet up in the middle of the ocean, and one ship transfers cargo to the other. This is a common way to avoid sanctions, and is often used to transfer oil from sanctioned countries to other countries. We're going to look at a few different ways to detect these transfers using AIS data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8KaPQHzqDnH"
      },
      "outputs": [],
      "source": [
        "%pip install duckdb duckdb-engine jupysql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guitAnAOqDnH"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# Import jupysql Jupyter extension to create SQL cells\n",
        "%load_ext sql\n",
        "%config SqlMagic.autopandas = True\n",
        "%config SqlMagic.feedback = False\n",
        "%config SqlMagic.displaycon = False\n",
        "%sql duckdb:///:memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-DmRkCYqDnH"
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "INSTALL httpfs;\n",
        "LOAD httpfs;\n",
        "INSTALL spatial;\n",
        "LOAD spatial;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxQlFWG7qDnH"
      },
      "source": [
        "## Step 1\n",
        "\n",
        "Create a spatial database using the following AIS data:\n",
        "\n",
        "https://storage.googleapis.com/qm2/casa0025_ships.csv\n",
        "\n",
        "Each row in this dataset is an AIS 'ping' indicating the position of a ship at a particular date/time, alongside vessel-level characteristics.\n",
        "\n",
        "It contains the following columns:\n",
        "* `vesselid`: A unique numerical identifier for each ship, like a license plate\n",
        "* `vessel_name`: The ship's name\n",
        "* `vsl_descr`: The ship's type\n",
        "* `dwt`: The ship's Deadweight Tonnage (how many tons it can carry)\n",
        "* `v_length`: The ship's length in meters\n",
        "* `draught`: How many meters deep the ship is draughting (how low it sits in the water). Effectively indicates how much cargo the ship is carrying\n",
        "* `sog`: Speed over Ground (in knots)\n",
        "* `date`: A timestamp for the AIS signal\n",
        "* `lat`: The latitude of the AIS signal (EPSG:4326)\n",
        "* `lon`: The longitude of the AIS signal (EPSG:4326)\n",
        "\n",
        "Create a table called 'ais' where each row is a different AIS ping, with no superfluous information. Construct a geometry column.\n",
        "\n",
        "Create a second table called 'vinfo' which contains vessel-level information with no superfluous information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xguis6BCqDnH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqVRph9WqDnH"
      },
      "source": [
        "## Step 2\n",
        "\n",
        "Use a spatial join to identify ship-to-ship transfers in this dataset.\n",
        "Two ships are considered to be conducting a ship to ship transfer IF:\n",
        "\n",
        "* They are within 500 meters of each other\n",
        "* For more than two hours\n",
        "* And their speed is lower than 1 knot\n",
        "\n",
        "Some things to consider: make sure you're not joining ships with themselves. Try working with subsets of the data first while you try different things out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncrEsDCsqDnH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}